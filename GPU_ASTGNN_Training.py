#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUä¼˜åŒ–ç‰ˆASTGNNè®­ç»ƒè„šæœ¬
åŒ…å«æ··åˆç²¾åº¦è®­ç»ƒã€å¤šGPUæ”¯æŒã€å¼‚æ­¥æ•°æ®ä¼ è¾“ç­‰GPUåŠ é€ŸåŠŸèƒ½
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import matplotlib.pyplot as plt
import logging
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import os
from tqdm import tqdm  # æ·»åŠ è¿›åº¦æ¡

# GPUåŠ é€Ÿç›¸å…³å¯¼å…¥
from torch.cuda.amp import GradScaler, autocast
import torch.backends.cudnn as cudnn

# å¯¼å…¥ASTGNNç›¸å…³æ¨¡å—
from ASTGNN import ASTGNNFactorModel
from ASTGNN_Loss import ASTGNNFactorLoss
from FactorValidation import FactorValidationFramework
from Enhanced_Factor_Analysis import ProfessionalBacktestAnalyzer

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'WenQuanYi Micro Hei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class GPUOptimizedASTGNNTrainer:
    """GPUä¼˜åŒ–çš„ASTGNNè®­ç»ƒå™¨"""
    
    def __init__(self, data_file: str = 'processed_astgnn_data.pt', config: Optional[Dict] = None):
        """åˆå§‹åŒ–GPUä¼˜åŒ–è®­ç»ƒå™¨"""
        self.data_file = data_file
        self.config = config or self._get_default_config()
        
        # GPUåŠ é€Ÿé…ç½®
        self._setup_gpu_acceleration()
        
        # è®¾å¤‡é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.gpu_count = torch.cuda.device_count()
        self._log_gpu_info()
        
        # æ··åˆç²¾åº¦è®­ç»ƒ - ä¸´æ—¶ç¦ç”¨ä»¥é¿å…æ•°æ®ç±»å‹å†²çª
        self.use_amp = False  # ä¸´æ—¶ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        self.scaler = GradScaler() if self.use_amp else None
        if self.use_amp:
            logger.info("âœ“ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)")
        else:
            logger.info("! æ··åˆç²¾åº¦è®­ç»ƒå·²ç¦ç”¨ï¼Œä½¿ç”¨FP32")
        
        # åŠ è½½æ•°æ®
        self.load_processed_data()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.optimizer = None
        self.scheduler = None
        self.criterion = None
        self.validator = None
        self.professional_analyzer = None
        
        # è®­ç»ƒè®°å½•
        self.train_losses = []
        self.val_losses = []
        self.train_r2_scores = []
        self.val_r2_scores = []
        
        logger.info("âœ“ GPUä¼˜åŒ–ASTGNNè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_gpu_acceleration(self):
        """é…ç½®GPUåŠ é€Ÿä¼˜åŒ–"""
        if torch.cuda.is_available():
            # å¯ç”¨cuDNNè‡ªåŠ¨è°ƒä¼˜
            cudnn.benchmark = True
            cudnn.deterministic = False  # æé«˜æ€§èƒ½ï¼Œé™ä½å¯é‡å¤æ€§
            
            # é¢„åˆ†é…GPUå†…å­˜
            torch.cuda.empty_cache()
            
            # è®¾ç½®CUDAå¼‚æ­¥å’ŒTF32
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            # è®¾ç½®å†…å­˜ç®¡ç†
            if hasattr(torch.cuda, 'set_per_process_memory_fraction'):
                torch.cuda.set_per_process_memory_fraction(0.9)  # ä½¿ç”¨90%æ˜¾å­˜
            
            logger.info("âœ“ GPUåŠ é€Ÿä¼˜åŒ–é…ç½®å®Œæˆ")
        else:
            logger.warning("âš  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    def _log_gpu_info(self):
        """è®°å½•GPUä¿¡æ¯"""
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        if torch.cuda.is_available():
            logger.info(f"GPUæ•°é‡: {self.gpu_count}")
            for i in range(self.gpu_count):
                props = torch.cuda.get_device_properties(i)
                logger.info(f"GPU {i}: {props.name}")
                logger.info(f"  æ˜¾å­˜: {props.total_memory / 1024**3:.1f} GB")
                logger.info(f"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")
    
    def _get_default_config(self) -> Dict:
        """è·å–ä¼˜åŒ–çš„è®­ç»ƒé…ç½® - ä¸“æ³¨é¢„æµ‹æ–¹å‘æ­£ç¡®æ€§"""
        return {
            # === æ ¸å¿ƒè®­ç»ƒå‚æ•°ä¼˜åŒ– ===
            'learning_rate': 3e-5,    # é™ä½åˆ°3e-5ï¼Œæ›´ç²¾ç»†è°ƒèŠ‚RankIC
            'weight_decay': 5e-4,     # é€‚åº¦L2æ­£åˆ™åŒ–
            'batch_size': 8,          # æ›´å°æ‰¹æ¬¡ï¼Œæ›´ç¨³å®šæ¢¯åº¦
            'epochs': 300,            # å¢åŠ è®­ç»ƒè½®æ•°
            'early_stopping_patience': 50,  # æ›´å¤§è€å¿ƒ
            'gradient_clip_norm': 1.0,     # é€‚åº¦æ¢¯åº¦è£å‰ª
            
            # === æŸå¤±å‡½æ•°æƒé‡ä¼˜åŒ– ===
            'orthogonal_penalty_weight': 0.01,   # é™ä½æ­£äº¤æƒ©ç½šï¼Œé¿å…è¿‡åº¦çº¦æŸ
            'time_weight_decay': 0.9,            # å¹³è¡¡å†å²å’Œå½“å‰æ•°æ®é‡è¦æ€§
            'rank_ic_weight': 25.0,              # å¤§å¹…å¢åŠ RankICæƒé‡ï¼Œå¼ºåˆ¶æ­£å‘é¢„æµ‹
            'distribution_weight': 0.5,          # åˆ†å¸ƒæ­£åˆ™åŒ–æƒé‡
            'variance_weight': 0.3,              # æ–¹å·®ç¨³å®šæ€§æƒé‡
            'direction_penalty_weight': 5.0,     # æ–¹å‘æƒ©ç½šæƒé‡
            
            # === æ¨¡å‹æ¶æ„ä¼˜åŒ– ===
            'sequence_length': 8,                # ç¼©çŸ­åºåˆ—é•¿åº¦ï¼Œä¸“æ³¨è¿‘æœŸæ¨¡å¼
            'num_risk_factors': 6,               # å‡å°‘é£é™©å› å­æ•°é‡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
            'dropout_rate': 0.4,                 # å¢å¼ºdropoutæ­£åˆ™åŒ–
            'use_layer_norm': True,              # å¯ç”¨å±‚å½’ä¸€åŒ–
            'use_residual_connections': False,    # ç¦ç”¨æ®‹å·®è¿æ¥ï¼Œç®€åŒ–æ¨¡å‹
            
            # === æ•°æ®å¤„ç†ä¼˜åŒ– ===
            'target_prediction_days': [1, 3, 5], # å¤šæœŸé¢„æµ‹ï¼Œæé«˜ç¨³å®šæ€§
            'factor_neutralization': True,       # å› å­ä¸­æ€§åŒ–å¤„ç†
            'outlier_clip_std': 3.0,            # å¼‚å¸¸å€¼è£å‰ªæ ‡å‡†å·®
            'rolling_standardization': True,     # æ»šåŠ¨æ ‡å‡†åŒ–
            
            # === éªŒè¯å’Œå›æµ‹ä¼˜åŒ– ===
            'validation_frequency': 3,           # æ›´é¢‘ç¹éªŒè¯
            'save_best_model': True,
            'model_save_path': 'optimized_astgnn_model.pth',
            'plot_results': True,
            'save_checkpoint_frequency': 10,     # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            
            # === ç›®æ ‡æ€§èƒ½æŒ‡æ ‡ ===
            'target_rank_ic': 0.08,             # ç›®æ ‡RankIC 
            'target_ic_ir': 0.8,                # ç›®æ ‡ICä¿¡æ¯æ¯”ç‡
            'target_win_rate': 0.6,             # ç›®æ ‡èƒœç‡
            'min_prediction_variance': 0.01,     # æœ€å°é¢„æµ‹æ–¹å·®è¦æ±‚
            
            # === GPUä¼˜åŒ–é…ç½® ===
            'use_amp': True,
            'num_workers': 4,
            'pin_memory': True,
            'compile_model': False,
            'gradient_accumulation_steps': 2,
            'prefetch_factor': 2,
            'persistent_workers': True,
            
            # === é«˜çº§è®­ç»ƒç­–ç•¥ä¼˜åŒ– ===
            'use_cosine_annealing': False,       # ç¦ç”¨ä½™å¼¦é€€ç«ï¼Œä½¿ç”¨ç¨³å®šå­¦ä¹ ç‡
            'warmup_epochs': 20,                 # é¢„çƒ­è½®æ•°
            'use_cyclic_lr': True,               # å¾ªç¯å­¦ä¹ ç‡
            'cyclic_lr_base': 1e-6,              # å¾ªç¯å­¦ä¹ ç‡æœ€å°å€¼
            'cyclic_lr_max': 1e-4,               # å¾ªç¯å­¦ä¹ ç‡æœ€å¤§å€¼
            'patience_factor': 0.8,              # å­¦ä¹ ç‡è¡°å‡å› å­
            'min_lr': 1e-7,                      # æœ€å°å­¦ä¹ ç‡
            
            # === å› å­è´¨é‡æ§åˆ¶ ===
            'min_factor_coverage': 0.8,         # æœ€å°å› å­è¦†ç›–ç‡
            'max_factor_correlation': 0.8,      # æœ€å¤§å› å­ç›¸å…³æ€§
            'factor_decay_half_life': 60,       # å› å­è¡°å‡åŠè¡°æœŸ(å¤©)
            'rebalance_frequency': 5,           # 5æ—¥è°ƒä»“é¢‘ç‡
            'transaction_cost': 0.001,          # äº¤æ˜“æˆæœ¬
        }
    
    def load_processed_data(self):
        """åŠ è½½é¢„å¤„ç†æ•°æ®"""
        logger.info(f"åŠ è½½é¢„å¤„ç†æ•°æ®: {self.data_file}")
        
        try:
            data_dict = torch.load(self.data_file, map_location='cpu')
            
            # æå–æ•°æ®
            self.data = data_dict['data']['sequences']
            self.metadata = data_dict['data']['metadata']
            self.preprocessing_config = data_dict['config']
            self.factor_scaler = data_dict['factor_scaler']
            self.return_scaler = data_dict['return_scaler']
            
            # æ•°æ®ç»´åº¦ä¿¡æ¯
            train_data = self.data['train']
            self.num_sequences = train_data['factor_sequences'].shape[0]
            self.sequence_length = train_data['factor_sequences'].shape[1]
            self.num_stocks = train_data['factor_sequences'].shape[2] 
            self.num_factors = train_data['factor_sequences'].shape[3]
            
            logger.info(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ:")
            logger.info(f"  è®­ç»ƒåºåˆ—æ•°: {self.num_sequences}")
            logger.info(f"  åºåˆ—é•¿åº¦: {self.sequence_length}")
            logger.info(f"  è‚¡ç¥¨æ•°é‡: {self.num_stocks}")
            logger.info(f"  å› å­æ•°é‡: {self.num_factors}")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            raise
    
    def create_gpu_optimized_data_loaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """åˆ›å»ºGPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨"""
        logger.info("================================================================================")
        logger.info("åˆ›å»ºGPUä¼˜åŒ–æ•°æ®åŠ è½½å™¨")
        
        # ğŸ”§ ä¿®å¤ï¼šåŠ¨æ€è°ƒæ•´batch_sizeä»¥é€‚åº”å°æ•°æ®é›†
        train_size = self.data['train']['factor_sequences'].shape[0]
        val_size = self.data['validation']['factor_sequences'].shape[0] 
        test_size = self.data['test']['factor_sequences'].shape[0]
        
        # æ ¹æ®æ•°æ®é›†å¤§å°åŠ¨æ€è°ƒæ•´batch_size
        max_batch_size = self.config['batch_size']
        train_batch_size = min(max_batch_size, max(1, train_size // 2))  # è‡³å°‘äº§ç”Ÿ2ä¸ªæ‰¹æ¬¡
        val_batch_size = min(max_batch_size, max(1, val_size))           # éªŒè¯é›†è‡³å°‘1ä¸ªæ‰¹æ¬¡
        test_batch_size = min(max_batch_size, max(1, test_size))         # æµ‹è¯•é›†è‡³å°‘1ä¸ªæ‰¹æ¬¡
        
        logger.info(f"åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´:")
        logger.info(f"  è®­ç»ƒ: {train_size}ä¸ªåºåˆ— â†’ batch_size={train_batch_size}")
        logger.info(f"  éªŒè¯: {val_size}ä¸ªåºåˆ— â†’ batch_size={val_batch_size}")
        logger.info(f"  æµ‹è¯•: {test_size}ä¸ªåºåˆ— â†’ batch_size={test_batch_size}")
        
        # GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨é…ç½®
        loader_config = {
            'num_workers': 6,
            'pin_memory': True,
            'persistent_workers': True,
            'drop_last': False,  # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¸ä¸¢å¼ƒä¸å®Œæ•´æ‰¹æ¬¡
            'prefetch_factor': 2
        }
        
        logger.info(f"æ•°æ®åŠ è½½å™¨é…ç½®: {loader_config}")
        
        # åˆ›å»ºæ•°æ®é›†
        train_dataset = TensorDataset(
            self.data['train']['factor_sequences'],
            self.data['train']['target_sequences']
        )
        val_dataset = TensorDataset(
            self.data['validation']['factor_sequences'],
            self.data['validation']['target_sequences']
        )
        test_dataset = TensorDataset(
            self.data['test']['factor_sequences'],
            self.data['test']['target_sequences']
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, **loader_config)
        val_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, **loader_config)
        test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, **loader_config)
        
        logger.info("âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
        logger.info(f"  è®­ç»ƒæ‰¹æ¬¡: {len(train_loader)}")
        logger.info(f"  éªŒè¯æ‰¹æ¬¡: {len(val_loader)}")
        logger.info(f"  æµ‹è¯•æ‰¹æ¬¡: {len(test_loader)}")
        
        return train_loader, val_loader, test_loader
    
    def initialize_gpu_optimized_model(self):
        """åˆå§‹åŒ–GPUä¼˜åŒ–çš„æ¨¡å‹å’Œä¼˜åŒ–å™¨"""
        logger.info("åˆå§‹åŒ–GPUä¼˜åŒ–ASTGNNæ¨¡å‹")
        
        # æ¨¡å‹é…ç½® - ç®€åŒ–æ¶æ„ï¼Œä¸“æ³¨é¢„æµ‹æ–¹å‘æ­£ç¡®æ€§
        model_config = {
            'sequential_input_size': self.num_factors,
            'gru_hidden_size': 12,            # å‹ç¼©éšè—å±‚ï¼Œé¿å…è¿‡æ‹Ÿåˆ
            'gru_num_layers': 1,              # å•å±‚GRU
            'gat_hidden_size': 24,            # å‡å°GATéšè—å±‚
            'gat_n_heads': 1,                 # å•æ³¨æ„åŠ›å¤´
            'res_hidden_size': 24,            # å‡å°æ®‹å·®å±‚
            'num_risk_factors': self.config.get('num_risk_factors', 6),  # ä½¿ç”¨é…ç½®å€¼
            'tgc_hidden_size': 24,            # å‡å°TGCå±‚
            'tgc_output_size': 12,            # å‹ç¼©è¾“å‡ºç»´åº¦
            'num_tgc_layers': 1,              # å•å±‚TGC
            'tgc_modes': ['add'],             # åªä½¿ç”¨åŠ æ³•æ¨¡å¼
            'prediction_hidden_sizes': [12],  # å‹ç¼©é¢„æµ‹å±‚
            'num_predictions': 1,             # å•å› å­è¾“å‡º
            'dropout': self.config.get('dropout_rate', 0.4),  # ä½¿ç”¨é…ç½®å€¼
            'verbose': False                  # ç®€åŒ–è¾“å‡º
        }
        
        # åˆ›å»ºæ¨¡å‹
        self.model = ASTGNNFactorModel(**model_config).to(self.device)
        
        # æ¨¡å‹ç¼–è¯‘ä¼˜åŒ– (PyTorch 2.0+)
        if self.config.get('compile_model', False) and hasattr(torch, 'compile'):
            try:
                self.model = torch.compile(self.model, mode='default')
                logger.info("âœ“ æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–å¯ç”¨")
            except Exception as e:
                logger.warning(f"âš  æ¨¡å‹ç¼–è¯‘å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹æ¨¡å‹: {e}")
        
        # å¤šGPUæ”¯æŒ
        if self.gpu_count > 1:
            self.model = nn.DataParallel(self.model)
            logger.info(f"âœ“ å¯ç”¨å¤šGPUè®­ç»ƒï¼ŒGPUæ•°é‡: {self.gpu_count}")
        
        # æ”¹è¿›æƒé‡åˆå§‹åŒ–
        self._initialize_model_weights()
        
        # ä¼˜åŒ–å™¨ - GPUä¼˜åŒ–é…ç½®
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay'],
            eps=1e-8,
            amsgrad=True
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä¼˜åŒ–ç‰ˆæœ¬
        if self.config.get('use_cyclic_lr', True):
            self.scheduler = optim.lr_scheduler.CyclicLR(
                self.optimizer,
                base_lr=self.config.get('cyclic_lr_base', 1e-6),
                max_lr=self.config.get('cyclic_lr_max', 1e-4),
                step_size_up=self.config['epochs'] // 10,
                mode='triangular2',
                cycle_momentum=False
            )
        else:
            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer,
                mode='min',
                factor=self.config.get('patience_factor', 0.8),
                patience=15,
                min_lr=self.config.get('min_lr', 1e-7)
            )
        
        # æŸå¤±å‡½æ•° - è¶…çº§ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨é¢„æµ‹æ–¹å‘æ­£ç¡®æ€§
        self.criterion = ASTGNNFactorLoss(
            omega=self.config.get('time_weight_decay', 0.9),      # æ—¶é—´è¡°å‡æƒé‡
            lambda_orthogonal=self.config.get('orthogonal_penalty_weight', 0.01),  # æ­£äº¤æƒ©ç½š
            lambda_rank_ic=self.config.get('rank_ic_weight', 10.0),    # RankICæƒé‡
            lambda_distribution=self.config.get('distribution_weight', 0.5),  # åˆ†å¸ƒæ­£åˆ™åŒ–
            lambda_variance=self.config.get('variance_weight', 0.3),    # æ–¹å·®ç¨³å®šæ€§
            max_periods=3,                       # åªå…³æ³¨å‰3æœŸé¢„æµ‹
            eps=1e-6,                           # æ•°å€¼ç¨³å®šæ€§
            regularization_type='frobenius'     # ä½¿ç”¨FrobeniusèŒƒæ•°
        )
        
        # å…¶ä»–ç»„ä»¶
        self.validator = FactorValidationFramework()
        self.professional_analyzer = ProfessionalBacktestAnalyzer(
                    start_date='20230101',
        end_date='20231231',
            factor_names=['ASTGNN_Factor']
        )
        
        # æ¨¡å‹å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        logger.info(f"âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"  æ€»å‚æ•°æ•°: {total_params:,}")
        logger.info(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        logger.info(f"  æ¨¡å‹é…ç½®: {model_config}")
    
    def _initialize_model_weights(self):
        """æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–"""
        logger.info("åº”ç”¨æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–")
        
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Linear):
                if 'prediction' in name.lower() or 'output' in name.lower():
                    nn.init.normal_(module.weight, mean=0.0, std=0.1)
                    if module.bias is not None:
                        nn.init.normal_(module.bias, mean=0.0, std=0.05)
                else:
                    nn.init.xavier_normal_(module.weight)
                    if module.bias is not None:
                        nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Conv1d):
                nn.init.kaiming_normal_(module.weight, mode='fan_out')
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, (nn.BatchNorm1d, nn.LayerNorm)):
                nn.init.ones_(module.weight)
                nn.init.zeros_(module.bias)
    
    def _compute_batch_loss(self, predictions, target_returns, batch_size):
        """è®¡ç®—æ‰¹æ¬¡æŸå¤± - å•å› å­ç‰ˆæœ¬"""
        batch_loss = 0.0
        
        for b in range(min(batch_size, 5)):  # é™åˆ¶æ‰¹æ¬¡æ•°ä»¥é¿å…å†…å­˜é—®é¢˜
            F = predictions[b]  # [num_stocks, 1] å•å› å­
            
            # æ„å»ºæœªæ¥å¤šæœŸæ”¶ç›Šç‡åˆ—è¡¨
            future_returns_list = []
            for t in range(target_returns.shape[1]):
                future_returns_list.append(target_returns[b, t])
            
            batch_loss += self.criterion(F, future_returns_list)
        
        return batch_loss / min(batch_size, 5)
    
    def train_epoch_gpu_optimized(self, train_loader: DataLoader, epoch: int) -> Tuple[float, float]:
        """GPUä¼˜åŒ–çš„è®­ç»ƒepoch"""
        self.model.train()
        total_loss = 0.0
        total_r2 = 0.0
        num_batches = len(train_loader)
        
        # æ¢¯åº¦ç´¯ç§¯é…ç½®
        accumulation_steps = self.config.get('gradient_accumulation_steps', 2)
        
        # é¢„çƒ­GPU
        if epoch == 1 and torch.cuda.is_available():
            logger.info("é¢„çƒ­GPU...")
            torch.cuda.synchronize()
        
        # æ·»åŠ è¿›åº¦æ¡
        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch:3d}', 
                           leave=False, ncols=90, 
                           bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')
        
        for batch_idx, (factor_sequences, target_returns) in enumerate(progress_bar):
            # å¼‚æ­¥æ•°æ®ä¼ è¾“åˆ°GPU
            factor_sequences = factor_sequences.to(self.device, non_blocking=True)
            target_returns = target_returns.to(self.device, non_blocking=True)
            
            batch_size = factor_sequences.shape[0]
            
            # åˆ›å»ºé‚»æ¥çŸ©é˜µï¼ˆç›´æ¥åœ¨GPUä¸Šï¼Œç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´ï¼‰
            adj_matrix = torch.eye(self.num_stocks, device=self.device, dtype=factor_sequences.dtype).unsqueeze(0).repeat(batch_size, 1, 1)
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            if self.use_amp:
                with autocast():
                    predictions, risk_factors, attention_weights, intermediate_outputs = self.model(factor_sequences, adj_matrix)
                    batch_loss = self._compute_batch_loss(predictions, target_returns, batch_size)
                    batch_loss = batch_loss / accumulation_steps
            else:
                predictions, risk_factors, attention_weights, intermediate_outputs = self.model(factor_sequences, adj_matrix)
                batch_loss = self._compute_batch_loss(predictions, target_returns, batch_size)
                batch_loss = batch_loss / accumulation_steps
            
            # åå‘ä¼ æ’­
            if self.use_amp:
                self.scaler.scale(batch_loss).backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['gradient_clip_norm'])
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
                    if self.scheduler:
                        self.scheduler.step()
            else:
                batch_loss.backward()
                
                if (batch_idx + 1) % accumulation_steps == 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['gradient_clip_norm'])
                    self.optimizer.step()
                    self.optimizer.zero_grad()
                    if self.scheduler:
                        self.scheduler.step()
            
            # è®¡ç®—RÂ²åˆ†æ•°
            with torch.no_grad():
                target_for_r2 = target_returns[:, 0, :]
                r2_score = self.calculate_r2_score(predictions.squeeze(-1), target_for_r2)
            
            total_loss += (batch_loss * accumulation_steps).item()
            total_r2 += r2_score
            
            # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
            current_lr = self.optimizer.param_groups[0]['lr']
            progress_bar.set_postfix({
                'Loss': f'{(batch_loss * accumulation_steps).item():.4f}',
                'RÂ²': f'{r2_score:.4f}',
                'LR': f'{current_lr:.1e}'
            })
        
        avg_loss = total_loss / num_batches
        avg_r2 = total_r2 / num_batches
        
        return avg_loss, avg_r2
    
    def validate_epoch_gpu_optimized(self, val_loader: DataLoader) -> Tuple[float, float]:
        """GPUä¼˜åŒ–çš„éªŒè¯epoch"""
        self.model.eval()
        total_loss = 0.0
        total_r2 = 0.0
        num_batches = len(val_loader)
        
        # å…³é”®ä¿®å¤ï¼šæ£€æŸ¥éªŒè¯æ•°æ®é›†æ˜¯å¦ä¸ºç©º
        if num_batches == 0:
            logger.warning("âš ï¸ éªŒè¯æ•°æ®é›†ä¸ºç©ºï¼Œè¿”å›é»˜è®¤å€¼")
            return 0.0, 0.0
        
        # æ·»åŠ éªŒè¯è¿›åº¦æ¡
        progress_bar = tqdm(val_loader, desc='Validating', 
                           leave=False, ncols=90,
                           bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]')
        
        with torch.no_grad():
            for factor_sequences, target_returns in progress_bar:
                # å¼‚æ­¥æ•°æ®ä¼ è¾“
                factor_sequences = factor_sequences.to(self.device, non_blocking=True)
                target_returns = target_returns.to(self.device, non_blocking=True)
                
                batch_size = factor_sequences.shape[0]
                adj_matrix = torch.eye(self.num_stocks, device=self.device, dtype=factor_sequences.dtype).unsqueeze(0).repeat(batch_size, 1, 1)
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                if self.use_amp:
                    with autocast():
                        predictions, risk_factors, attention_weights, intermediate_outputs = self.model(factor_sequences, adj_matrix)
                        batch_loss = self._compute_batch_loss(predictions, target_returns, batch_size)
                else:
                    predictions, risk_factors, attention_weights, intermediate_outputs = self.model(factor_sequences, adj_matrix)
                    batch_loss = self._compute_batch_loss(predictions, target_returns, batch_size)
                
                # è®¡ç®—RÂ²åˆ†æ•°
                target_for_r2 = target_returns[:, 0, :]
                r2_score = self.calculate_r2_score(predictions.squeeze(-1), target_for_r2)
                
                total_loss += batch_loss.item()
                total_r2 += r2_score
                
                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                progress_bar.set_postfix({
                    'Loss': f'{batch_loss.item():.4f}',
                    'RÂ²': f'{r2_score:.4f}'
                })
        
        avg_loss = total_loss / num_batches
        avg_r2 = total_r2 / num_batches
        
        return avg_loss, avg_r2
    
    def calculate_r2_score(self, predictions: torch.Tensor, targets: torch.Tensor) -> float:
        """è®¡ç®—RÂ²åˆ†æ•°"""
        pred_flat = predictions.reshape(-1)
        target_flat = targets.reshape(-1)
        
        mask = ~(torch.isnan(pred_flat) | torch.isnan(target_flat))
        if mask.sum() == 0:
            return 0.0
        
        pred_clean = pred_flat[mask]
        target_clean = target_flat[mask]
        
        ss_res = torch.sum((target_clean - pred_clean) ** 2)
        ss_tot = torch.sum((target_clean - torch.mean(target_clean)) ** 2)
        
        if ss_tot == 0:
            return 0.0
        
        r2 = 1 - (ss_res / ss_tot)
        return r2.item()
    
    def train_model_gpu_optimized(self):
        """GPUä¼˜åŒ–çš„å®Œæ•´è®­ç»ƒæµç¨‹"""
        logger.info("å¼€å§‹GPUä¼˜åŒ–ASTGNNæ¨¡å‹è®­ç»ƒ")
        logger.info("=" * 80)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, test_loader = self.create_gpu_optimized_data_loaders()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.initialize_gpu_optimized_model()
        
        # è®­ç»ƒå‚æ•°
        best_val_loss = float('inf')
        patience_counter = 0
        start_time = time.time()
        
        # GPUé¢„çƒ­
        if torch.cuda.is_available():
            torch.cuda.synchronize()
            logger.info("âœ“ GPUé¢„çƒ­å®Œæˆ")
        
        for epoch in range(1, self.config['epochs'] + 1):
            epoch_start_time = time.time()
            
            # è®­ç»ƒ
            train_loss, train_r2 = self.train_epoch_gpu_optimized(train_loader, epoch)
            
            # éªŒè¯
            if epoch % self.config['validation_frequency'] == 0:
                val_loss, val_r2 = self.validate_epoch_gpu_optimized(val_loader)
                
                # è®°å½•å†å²
                self.train_losses.append(train_loss)
                self.val_losses.append(val_loss)
                self.train_r2_scores.append(train_r2)
                self.val_r2_scores.append(val_r2)
                
                epoch_time = time.time() - epoch_start_time
                current_lr = self.optimizer.param_groups[0]['lr']
                
                logger.info(f"Epoch {epoch}/{self.config['epochs']} "
                           f"[{epoch_time:.2f}s] - "
                           f"Train Loss: {train_loss:.6f}, Train RÂ²: {train_r2:.6f}, "
                           f"Val Loss: {val_loss:.6f}, Val RÂ²: {val_r2:.6f}, "
                           f"LR: {current_lr:.2e}")
                
                # æ—©åœæœºåˆ¶
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    patience_counter = 0
                    
                    if self.config['save_best_model']:
                        self.save_model(self.config['model_save_path'])
                        logger.info(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹: {self.config['model_save_path']}")
                else:
                    patience_counter += 1
                
                if patience_counter >= self.config['early_stopping_patience']:
                    logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨epoch {epoch}")
                    break
            else:
                epoch_time = time.time() - epoch_start_time
                current_lr = self.optimizer.param_groups[0]['lr']
                logger.info(f"Epoch {epoch}/{self.config['epochs']} "
                           f"[{epoch_time:.2f}s] - "
                           f"Train Loss: {train_loss:.6f}, Train RÂ²: {train_r2:.6f}, "
                           f"LR: {current_lr:.2e}")
        
        total_time = time.time() - start_time
        logger.info(f"âœ“ è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # GPUæœ€ç»ˆåŒæ­¥
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        
        # æœ€ç»ˆæµ‹è¯•
        self.final_evaluation(test_loader)
        
        # ç”Ÿæˆå› å­åˆ†ææ•°æ®
        self.generate_factor_analysis_data(test_loader)
        
        # ç»˜åˆ¶ç»“æœ
        if self.config['plot_results']:
            self.plot_training_results()
    
    def final_evaluation(self, test_loader: DataLoader):
        """æœ€ç»ˆè¯„ä¼°"""
        logger.info("è¿›è¡Œæœ€ç»ˆæµ‹è¯•è¯„ä¼°")
        
        if os.path.exists(self.config['model_save_path']):
            self.load_model(self.config['model_save_path'])
        
        test_loss, test_r2 = self.validate_epoch_gpu_optimized(test_loader)
        
        logger.info(f"âœ“ æœ€ç»ˆæµ‹è¯•ç»“æœ:")
        logger.info(f"  æµ‹è¯•æŸå¤±: {test_loss:.6f}")
        logger.info(f"  æµ‹è¯•RÂ²: {test_r2:.6f}")
    
    def generate_factor_analysis_data(self, test_loader: DataLoader):
        """ç”Ÿæˆå› å­åˆ†ææ•°æ®ç”¨äºåç»­è¯„ä»·"""
        logger.info("ç”Ÿæˆå› å­åˆ†ææ•°æ®...")
        
        # ç¡®ä¿ä½¿ç”¨æœ€ä½³æ¨¡å‹
        if os.path.exists(self.config['model_save_path']):
            self.load_model(self.config['model_save_path'])
        
        self.model.eval()
        all_factors = []
        all_targets = []
        
        with torch.no_grad():
            for factor_sequences, target_returns in test_loader:
                # GPUä¼˜åŒ–æ•°æ®ä¼ è¾“
                factor_sequences = factor_sequences.to(self.device, non_blocking=True)
                target_returns = target_returns.to(self.device, non_blocking=True)
                
                # åˆ›å»ºé‚»æ¥çŸ©é˜µ
                batch_size = factor_sequences.shape[0]
                adj_matrix = torch.eye(self.num_stocks, device=self.device, dtype=factor_sequences.dtype).unsqueeze(0).repeat(batch_size, 1, 1)
                
                # å‰å‘ä¼ æ’­è·å–å› å­é¢„æµ‹
                predictions, risk_factors, attention_weights, intermediate_outputs = self.model(factor_sequences, adj_matrix)
                
                # å¿«é€Ÿä¿®å¤ï¼šå°†å› å­é¢„æµ‹å–åä»¥çº æ­£æ–¹å‘
                predictions = -predictions
                
                # æ”¶é›†å› å­å’Œç›®æ ‡æ•°æ®
                # predictionså½¢çŠ¶: [batch_size, num_stocks, 1] (å•å› å­)
                # target_returnså½¢çŠ¶: [batch_size, prediction_horizon, num_stocks]
                
                # è½¬æ¢ä¸º [time, stocks, factors] æ ¼å¼
                for b in range(batch_size):
                    # å› å­æ•°æ®: [num_stocks, 1] -> [1, num_stocks, 1]
                    factors_b = predictions[b].unsqueeze(0)  # [1, num_stocks, 1]
                    all_factors.append(factors_b.cpu())
                    
                    # ç›®æ ‡æ•°æ®: [prediction_horizon, num_stocks] -> [prediction_horizon, num_stocks]
                    targets_b = target_returns[b].permute(0, 1)  # [prediction_horizon, num_stocks]
                    all_targets.append(targets_b.cpu())
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®
        try:
            # æ‹¼æ¥å› å­æ•°æ®: list of [1, num_stocks, 1] -> [total_time, num_stocks, 1]
            factors_tensor = torch.cat(all_factors, dim=0)
            
            # æ‹¼æ¥ç›®æ ‡æ•°æ®: list of [prediction_horizon, num_stocks] -> [total_batches*prediction_horizon, num_stocks]
            targets_tensor = torch.cat(all_targets, dim=0)
            
            # è°ƒæ•´ç›®æ ‡æ•°æ®ç»´åº¦ä»¥åŒ¹é…å› å­æ•°æ®çš„æ—¶é—´ç»´åº¦
            time_steps = factors_tensor.shape[0]
            targets_tensor = targets_tensor[:time_steps]  # æˆªå–åŒ¹é…çš„æ—¶é—´æ­¥æ•°
            
            # è½¬æ¢ä¸ºnumpy
            factors_np = factors_tensor.numpy()  # [time, stocks, factors]
            targets_np = targets_tensor.numpy()  # [time, stocks]
            
            logger.info(f"å› å­æ•°æ®ç”Ÿæˆå®Œæˆ:")
            logger.info(f"  å› å­å½¢çŠ¶: {factors_np.shape}")
            logger.info(f"  ç›®æ ‡å½¢çŠ¶: {targets_np.shape}")
            logger.info(f"  æ—¶é—´æ­¥æ•°: {factors_np.shape[0]}")
            logger.info(f"  è‚¡ç¥¨æ•°é‡: {factors_np.shape[1]}")
            logger.info(f"  å› å­æ•°é‡: {factors_np.shape[2]} (å•å› å­)")
            
            # ä¿å­˜å› å­å’Œç›®æ ‡æ•°æ®ç”¨äºè¿›ä¸€æ­¥åˆ†æ
            np.savez('factor_analysis_data.npz', 
                     factors=factors_np,  # [time, stocks, 1] å•å› å­
                     targets=targets_np)  # [time, stocks]
            
            logger.info("âœ“ å› å­åˆ†ææ•°æ®å·²ä¿å­˜åˆ° factor_analysis_data.npz")
            
        except Exception as e:
            logger.error(f"å› å­æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
    
    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,
            'config': self.config,
            'metadata': self.metadata,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'train_r2_scores': self.train_r2_scores,
            'val_r2_scores': self.val_r2_scores
        }, path)
    
    def load_model(self, path: str):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        if checkpoint.get('optimizer_state_dict'):
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if checkpoint.get('scheduler_state_dict') and self.scheduler:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        if checkpoint.get('scaler_state_dict') and self.scaler:
            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])
    
    def plot_training_results(self):
        """ç»˜åˆ¶è®­ç»ƒç»“æœ"""
        logger.info("ç»˜åˆ¶è®­ç»ƒç»“æœå›¾è¡¨")
        
        results_dir = "training_results"
        os.makedirs(results_dir, exist_ok=True)
        
        plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('GPUä¼˜åŒ–ASTGNNè®­ç»ƒç»“æœ', fontsize=16, fontweight='bold')
        
        # æŸå¤±æ›²çº¿
        epochs = range(1, len(self.train_losses) + 1)
        ax1.plot(epochs, self.train_losses, 'b-', label='è®­ç»ƒæŸå¤±', alpha=0.8, linewidth=2)
        ax1.plot(epochs, self.val_losses, 'r-', label='éªŒè¯æŸå¤±', alpha=0.8, linewidth=2)
        ax1.set_title('æŸå¤±æ›²çº¿')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('æŸå¤±')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # RÂ²åˆ†æ•°æ›²çº¿
        ax2.plot(epochs, self.train_r2_scores, 'b-', label='è®­ç»ƒRÂ²', alpha=0.8, linewidth=2)
        ax2.plot(epochs, self.val_r2_scores, 'r-', label='éªŒè¯RÂ²', alpha=0.8, linewidth=2)
        ax2.set_title('RÂ²åˆ†æ•°æ›²çº¿')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('RÂ²åˆ†æ•°')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        
        # GPUåˆ©ç”¨ç‡ä¿¡æ¯
        gpu_info = f"""GPUé…ç½®ä¿¡æ¯:
â€¢ è®¾å¤‡: {self.device}
â€¢ GPUæ•°é‡: {self.gpu_count}
â€¢ æ··åˆç²¾åº¦: {'å¯ç”¨' if self.use_amp else 'ç¦ç”¨'}
â€¢ æ‰¹æ¬¡å¤§å°: {self.config['batch_size']}
â€¢ å·¥ä½œè¿›ç¨‹: {self.config.get('num_workers', 0)}
â€¢ ç¼–è¯‘ä¼˜åŒ–: {'å¯ç”¨' if self.config.get('compile_model') else 'ç¦ç”¨'}
"""
        
        ax3.text(0.05, 0.95, gpu_info, transform=ax3.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", 
                facecolor="lightgreen", alpha=0.7))
        ax3.set_title('GPUé…ç½®ä¿¡æ¯')
        ax3.axis('off')
        
        # è®­ç»ƒç»Ÿè®¡
        stats_text = f"""è®­ç»ƒæ‘˜è¦:
â€¢ æœ€ä½³éªŒè¯æŸå¤±: {min(self.val_losses):.6f}
â€¢ æœ€ä½³éªŒè¯RÂ²: {max(self.val_r2_scores):.6f}
â€¢ æ€»è½®æ•°: {len(self.train_losses)}
â€¢ è‚¡ç¥¨æ•°: {self.num_stocks:,}
â€¢ å› å­æ•°: {self.num_factors}
â€¢ æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}
â€¢ å•å› å­è¾“å‡º: âœ“
"""
        
        ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes, fontsize=11,
                verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", 
                facecolor="lightblue", alpha=0.7))
        ax4.set_title('è®­ç»ƒç»Ÿè®¡')
        ax4.axis('off')
        
        plt.tight_layout()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'gpu_astgnn_training_results_{timestamp}.png'
        save_path = os.path.join(results_dir, filename)
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
        logger.info(f"âœ“ è®­ç»ƒç»“æœå›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        plt.show()


def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¯åŠ¨GPUä¼˜åŒ–ASTGNNè®­ç»ƒ")
    
    # ä½¿ç”¨ä¼˜åŒ–çš„è®­ç»ƒé…ç½® - ä¸“æ³¨é¢„æµ‹æ–¹å‘æ­£ç¡®æ€§
    config = {
        # åŸºç¡€è®­ç»ƒå‚æ•° - ä¼˜åŒ–ç‰ˆæœ¬
        'learning_rate': 3e-5,    # é™ä½åˆ°3e-5ï¼Œæ›´ç²¾ç»†è°ƒèŠ‚RankIC
        'weight_decay': 5e-4,     # é€‚åº¦L2æ­£åˆ™åŒ–
        'batch_size': 8,          # æ›´å°æ‰¹æ¬¡ï¼Œæ›´ç¨³å®šæ¢¯åº¦
        'epochs': 100,            # å¢åŠ è®­ç»ƒè½®æ•°
        'early_stopping_patience': 50,  # æ›´å¤§è€å¿ƒ
        'gradient_clip_norm': 1.0,     # é€‚åº¦æ¢¯åº¦è£å‰ª
        'orthogonal_penalty_weight': 0.01,   # é™ä½æ­£äº¤æƒ©ç½šï¼Œé¿å…è¿‡åº¦çº¦æŸ
        'time_weight_decay': 0.9,            # å¹³è¡¡å†å²å’Œå½“å‰æ•°æ®é‡è¦æ€§
        'rank_ic_weight': 25.0,              # å¤§å¹…å¢åŠ RankICæƒé‡ï¼Œå¼ºåˆ¶æ­£å‘é¢„æµ‹
        'distribution_weight': 0.5,          # åˆ†å¸ƒæ­£åˆ™åŒ–æƒé‡
        'variance_weight': 0.3,              # æ–¹å·®ç¨³å®šæ€§æƒé‡
        'validation_frequency': 3,           # æ›´é¢‘ç¹éªŒè¯
        'save_best_model': True,
        'model_save_path': 'optimized_astgnn_model.pth',
        'plot_results': True,
        
        # æ¨¡å‹æ¶æ„ä¼˜åŒ–
        'sequence_length': 8,                # ç¼©çŸ­åºåˆ—é•¿åº¦ï¼Œä¸“æ³¨è¿‘æœŸæ¨¡å¼
        'num_risk_factors': 6,               # å‡å°‘é£é™©å› å­æ•°é‡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        'dropout_rate': 0.4,                 # å¢å¼ºdropoutæ­£åˆ™åŒ–
        'use_layer_norm': True,              # å¯ç”¨å±‚å½’ä¸€åŒ–
        'use_residual_connections': False,    # ç¦ç”¨æ®‹å·®è¿æ¥ï¼Œç®€åŒ–æ¨¡å‹
        
        # é«˜çº§è®­ç»ƒç­–ç•¥
        'use_cosine_annealing': False,       # ç¦ç”¨ä½™å¼¦é€€ç«ï¼Œä½¿ç”¨ç¨³å®šå­¦ä¹ ç‡
        'warmup_epochs': 20,                 # é¢„çƒ­è½®æ•°
        'use_cyclic_lr': True,               # å¾ªç¯å­¦ä¹ ç‡
        'cyclic_lr_base': 1e-6,              # å¾ªç¯å­¦ä¹ ç‡æœ€å°å€¼
        'cyclic_lr_max': 1e-4,               # å¾ªç¯å­¦ä¹ ç‡æœ€å¤§å€¼
        'patience_factor': 0.8,              # å­¦ä¹ ç‡è¡°å‡å› å­
        'min_lr': 1e-7,                      # æœ€å°å­¦ä¹ ç‡
        
        # ä¸“ä¸šå›æµ‹ç›®æ ‡é…ç½® - ä¸¥æ ¼å¯¹æ ‡
        'target_annual_return': 0.36,    # ç›®æ ‡å¹´åŒ–æ”¶ç›Š36%
        'target_sharpe_ratio': 4.19,     # ç›®æ ‡å¤æ™®æ¯”ç‡4.19
        'target_max_drawdown': -0.16,    # ç›®æ ‡æœ€å¤§å›æ’¤-16%
        'target_calmar_ratio': 1.74,     # ç›®æ ‡Calmaræ¯”ç‡1.74
        'target_win_rate': 0.65,         # ç›®æ ‡èƒœç‡65%
        'rebalance_frequency': 10,       # 10æ—¥è°ƒä»“
        'transaction_cost': 0.0005,      # é™ä½äº¤æ˜“æˆæœ¬å‡è®¾
        'position_limit': 0.05,          # å•è‚¡æœ€å¤§æŒä»“5%
        'long_only': True,               # ä»…å¤šå¤´ç­–ç•¥ï¼Œé™ä½é£é™©
        'top_quantile': 0.2,             # é€‰æ‹©å‰20%è‚¡ç¥¨
        
        # GPUä¼˜åŒ–é…ç½®
        'use_amp': True,
        'num_workers': 6,
        'pin_memory': True,
        'compile_model': False,  # æš‚æ—¶å…³é—­æ¨¡å‹ç¼–è¯‘ï¼Œæé«˜ç¨³å®šæ€§
        'gradient_accumulation_steps': 4,  # å¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼Œæ¨¡æ‹Ÿæ›´å¤§æ‰¹æ¬¡
        'prefetch_factor': 2,
        'persistent_workers': True,
        
        # æ•°æ®è´¨é‡æ§åˆ¶
        'outlier_removal': True,         # å¯ç”¨å¼‚å¸¸å€¼ç§»é™¤
        'factor_normalization': True,    # å¯ç”¨å› å­æ ‡å‡†åŒ–
        'return_winsorize': True,        # æ”¶ç›Šç‡ç¼©å°¾å¤„ç†
        'risk_budget': 0.15,             # é£é™©é¢„ç®—15%
    }
    
    # åˆ›å»ºGPUä¼˜åŒ–è®­ç»ƒå™¨
    trainer = GPUOptimizedASTGNNTrainer(
        data_file='processed_astgnn_data.pt',
        config=config
    )
    
    # å¼€å§‹GPUä¼˜åŒ–è®­ç»ƒ
    trainer.train_model_gpu_optimized()
    
    logger.info("âœ“ GPUä¼˜åŒ–è®­ç»ƒå®Œæˆ")


if __name__ == "__main__":
    main() 